



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>Change detection - Advanced Data Mining</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.982221ab.css">
      
      
    
    
      <script src="../../assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#kolmogorov-smirnov-test" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../.." title="Advanced Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Advanced Data Mining
            </span>
            <span class="md-header-nav__topic">
              Change detection
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../.." title="Advanced Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Advanced Data Mining
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Advanced Data Mining" class="md-nav__link">
      Advanced Data Mining
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Change Detection
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Change Detection
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Change detection
      </label>
    
    <a href="./" title="Change detection" class="md-nav__link md-nav__link--active">
      Change detection
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#kolmogorov-smirnov-test" title="Kolmogorov-Smirnov Test" class="md-nav__link">
    Kolmogorov-Smirnov Test
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-cdfs-and-their-absolute-differences-are-calculated-below" title="The CDFs and their absolute differences are calculated below" class="md-nav__link">
    The CDFs and their absolute differences are calculated below
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#below-is-a-visualization-of-the-cdfs-and-their-absolute-differences" title="Below is a visualization of the CDFs and their absolute differences" class="md-nav__link">
    Below is a visualization of the CDFs and their absolute differences
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-the-distance-between-two-probability-distributions-kulback-leibler-divergence" title="Finding the distance between two probability distributions: Kulback-Leibler Divergence" class="md-nav__link">
    Finding the distance between two probability distributions: Kulback-Leibler Divergence
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-kl-divergence-between-p-and-q-is-0242" title="The KL Divergence between P and Q is 0.242" class="md-nav__link">
    The KL Divergence between P and Q is 0.242
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-kl-divergence-between-q-and-p-is-0314" title="The KL Divergence between Q and P is 0.314" class="md-nav__link">
    The KL Divergence between Q and P is 0.314
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Clustream
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Clustream
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Clustream/clustream/" title="Clustream" class="md-nav__link">
      Clustream
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Fading Function
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Fading Function
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Fading Function/fading_function/" title="Fading Function" class="md-nav__link">
      Fading Function
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Simple Statistics
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Simple Statistics
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Simple Statistics/simple_statistics/" title="Simple statistics" class="md-nav__link">
      Simple statistics
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#kolmogorov-smirnov-test" title="Kolmogorov-Smirnov Test" class="md-nav__link">
    Kolmogorov-Smirnov Test
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-cdfs-and-their-absolute-differences-are-calculated-below" title="The CDFs and their absolute differences are calculated below" class="md-nav__link">
    The CDFs and their absolute differences are calculated below
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#below-is-a-visualization-of-the-cdfs-and-their-absolute-differences" title="Below is a visualization of the CDFs and their absolute differences" class="md-nav__link">
    Below is a visualization of the CDFs and their absolute differences
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-the-distance-between-two-probability-distributions-kulback-leibler-divergence" title="Finding the distance between two probability distributions: Kulback-Leibler Divergence" class="md-nav__link">
    Finding the distance between two probability distributions: Kulback-Leibler Divergence
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-kl-divergence-between-p-and-q-is-0242" title="The KL Divergence between P and Q is 0.242" class="md-nav__link">
    The KL Divergence between P and Q is 0.242
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-kl-divergence-between-q-and-p-is-0314" title="The KL Divergence between Q and P is 0.314" class="md-nav__link">
    The KL Divergence between Q and P is 0.314
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Change detection</h1>
                
                <pre><code class="python">import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import rcParams

rcParams['figure.figsize'] = 11.7,8.27
sns.set()
</code></pre>

<p>In order to detect change between two windows of a stream S, we test if the P(x) in the current window is different from the P(x) in the previous window
Drift has occurred if P(x)ti != P(x)ti+1</p>
<p>To determine if the change in the observed P(x) is the sign of a drift, and that it is not just due to chance, a significance test can be used.</p>
<h2 id="kolmogorov-smirnov-test">Kolmogorov-Smirnov Test</h2>
<p>Given below are the observed frequencies of grades obtained by a sample of OVGU students in 2018 and 2019.</p>
<pre><code class="python">d = {'2018':[9, 5, 12, 18, 16, 12, 15, 5, 2, 6], 
     '2019':[4, 18, 18, 13, 12, 7, 9, 3, 12, 2],
     'Grade': [1.0, 1.3, 1.7, 2.0, 2.3, 2.7, 3.0, 3.3, 3.7, 4.0]}
grades = pd.DataFrame(d).set_index('Grade')
grades
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2018</th>
      <th>2019</th>
    </tr>
    <tr>
      <th>Grade</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>9</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>5</td>
      <td>18</td>
    </tr>
    <tr>
      <th>1.7</th>
      <td>12</td>
      <td>18</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>18</td>
      <td>13</td>
    </tr>
    <tr>
      <th>2.3</th>
      <td>16</td>
      <td>12</td>
    </tr>
    <tr>
      <th>2.7</th>
      <td>12</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>15</td>
      <td>9</td>
    </tr>
    <tr>
      <th>3.3</th>
      <td>5</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3.7</th>
      <td>2</td>
      <td>12</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>6</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<p>Tirtha believes that the grades of the students have improved from last year (drift). However, Vishnu is skeptical and suspects that the shift in grades is very small and not significant enough to conclude that anything has improved.</p>
<p>The Kolmogorov-Smirnov Test can help them determine who is right.</p>
<p><strong>KS Test Steps:</strong>
1. Calculate the CDFs of both the distributions
2. Find the maximum absolute difference max|D| between the two CDFS
3. Compare max|D| with the critical value at a desired alpha obtained from the KS table.
4. Conclude that the change is significant if max|D| &gt; critical value</p>
<pre><code class="python">grades['proportion (2018)'] = grades['2018'].apply(lambda x: x/grades['2018'].sum())
grades['proportion (2019)'] = grades['2019'].apply(lambda x: x/grades['2019'].sum())
grades
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2018</th>
      <th>2019</th>
      <th>proportion (2018)</th>
      <th>proportion (2019)</th>
    </tr>
    <tr>
      <th>Grade</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>9</td>
      <td>4</td>
      <td>0.09</td>
      <td>0.040816</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>5</td>
      <td>18</td>
      <td>0.05</td>
      <td>0.183673</td>
    </tr>
    <tr>
      <th>1.7</th>
      <td>12</td>
      <td>18</td>
      <td>0.12</td>
      <td>0.183673</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>18</td>
      <td>13</td>
      <td>0.18</td>
      <td>0.132653</td>
    </tr>
    <tr>
      <th>2.3</th>
      <td>16</td>
      <td>12</td>
      <td>0.16</td>
      <td>0.122449</td>
    </tr>
    <tr>
      <th>2.7</th>
      <td>12</td>
      <td>7</td>
      <td>0.12</td>
      <td>0.071429</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>15</td>
      <td>9</td>
      <td>0.15</td>
      <td>0.091837</td>
    </tr>
    <tr>
      <th>3.3</th>
      <td>5</td>
      <td>3</td>
      <td>0.05</td>
      <td>0.030612</td>
    </tr>
    <tr>
      <th>3.7</th>
      <td>2</td>
      <td>12</td>
      <td>0.02</td>
      <td>0.122449</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>6</td>
      <td>2</td>
      <td>0.06</td>
      <td>0.020408</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="the-cdfs-and-their-absolute-differences-are-calculated-below">The CDFs and their absolute differences are calculated below</h4>
<pre><code class="python">grades['cdf (2018)'] = grades['proportion (2018)'].cumsum()
grades['cdf (2019)'] = grades['proportion (2019)'].cumsum()
grades['D'] = grades.apply(lambda x: np.round(np.abs(x['cdf (2018)'] - x['cdf (2019)']), 2), axis=1)
grades
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2018</th>
      <th>2019</th>
      <th>proportion (2018)</th>
      <th>proportion (2019)</th>
      <th>cdf (2018)</th>
      <th>cdf (2019)</th>
      <th>D</th>
    </tr>
    <tr>
      <th>Grade</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>9</td>
      <td>4</td>
      <td>0.09</td>
      <td>0.040816</td>
      <td>0.09</td>
      <td>0.040816</td>
      <td>0.05</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>5</td>
      <td>18</td>
      <td>0.05</td>
      <td>0.183673</td>
      <td>0.14</td>
      <td>0.224490</td>
      <td>0.08</td>
    </tr>
    <tr>
      <th>1.7</th>
      <td>12</td>
      <td>18</td>
      <td>0.12</td>
      <td>0.183673</td>
      <td>0.26</td>
      <td>0.408163</td>
      <td>0.15</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>18</td>
      <td>13</td>
      <td>0.18</td>
      <td>0.132653</td>
      <td>0.44</td>
      <td>0.540816</td>
      <td>0.10</td>
    </tr>
    <tr>
      <th>2.3</th>
      <td>16</td>
      <td>12</td>
      <td>0.16</td>
      <td>0.122449</td>
      <td>0.60</td>
      <td>0.663265</td>
      <td>0.06</td>
    </tr>
    <tr>
      <th>2.7</th>
      <td>12</td>
      <td>7</td>
      <td>0.12</td>
      <td>0.071429</td>
      <td>0.72</td>
      <td>0.734694</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>15</td>
      <td>9</td>
      <td>0.15</td>
      <td>0.091837</td>
      <td>0.87</td>
      <td>0.826531</td>
      <td>0.04</td>
    </tr>
    <tr>
      <th>3.3</th>
      <td>5</td>
      <td>3</td>
      <td>0.05</td>
      <td>0.030612</td>
      <td>0.92</td>
      <td>0.857143</td>
      <td>0.06</td>
    </tr>
    <tr>
      <th>3.7</th>
      <td>2</td>
      <td>12</td>
      <td>0.02</td>
      <td>0.122449</td>
      <td>0.94</td>
      <td>0.979592</td>
      <td>0.04</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>6</td>
      <td>2</td>
      <td>0.06</td>
      <td>0.020408</td>
      <td>1.00</td>
      <td>1.000000</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="below-is-a-visualization-of-the-cdfs-and-their-absolute-differences">Below is a visualization of the CDFs and their absolute differences</h4>
<pre><code class="python">sns.lineplot(data=grades, y=&quot;cdf (2018)&quot;, x=grades.index)
sns.lineplot(data=grades, y=&quot;cdf (2019)&quot;, x=grades.index)

def plot_diff_line(index, row):
    plt.plot([index, index], [row['cdf (2019)'], row['cdf (2018)']], color='r', linestyle='-', linewidth=2)
    plt.ylabel(&quot;Probability&quot;)


for index, row in grades.iterrows():
    plot_diff_line(index, row)


plt.annotate('Max Difference', xy=(1.7, 0.3), xytext=(2, 0.35), 
             arrowprops=dict(facecolor='black', shrink=0.05)
            )
</code></pre>

<pre><code>Text(2,0.35,'Max Difference')
</code></pre>
<p><img alt="png" src="../output_8_1.png" /></p>
<p>The Max|D| between the two CDFs is 0.15</p>
<p>From the KS table, the critical value at alpha 0.05 is 1.36/root(n) = 0.136</p>
<p>Since Max|D| &gt; critical value, with 95% confidence, we reject the null hypothesis that the two distributions do not differ, which means we can say that OVGU grades have improved. Tirtha was right.</p>
<p>However, Vishnu contests this and says that 95% confidence isn't good enough. He recommends that they be 99% confident before making such a claim about the improvement in grades.
So, they look at the KS table again, and they get the critical value at alpha 0.01, which is 1.63/root(n) = 0.163</p>
<p>This time, Max|D| &lt; critical value with 99%; therefore, with 99% confidence, we fail to reject the null hypothesis that the two distributions do not differ, which means that the shift in grades might be due to chance, and the distribution might not have drifted</p>
<h2 id="finding-the-distance-between-two-probability-distributions-kulback-leibler-divergence">Finding the distance between two probability distributions: Kulback-Leibler Divergence</h2>
<p>This is a measure to calculate the distance between two probability distributions. 
Note: this isn't a distance metric because it violates the symmetry and triangle inequality properties of distance metrics.
We will use the same grade distributions from earlier.</p>
<pre><code class="python">d = {'2018':[9, 5, 12, 18, 16, 12, 15, 5, 2, 6], 
     '2019':[4, 18, 18, 13, 12, 7, 9, 3, 12, 2],
     'Grade': [1.0, 1.3, 1.7, 2.0, 2.3, 2.7, 3.0, 3.3, 3.7, 4.0]}
grades = pd.DataFrame(d).set_index('Grade')
grades
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2018</th>
      <th>2019</th>
    </tr>
    <tr>
      <th>Grade</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>9</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>5</td>
      <td>18</td>
    </tr>
    <tr>
      <th>1.7</th>
      <td>12</td>
      <td>18</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>18</td>
      <td>13</td>
    </tr>
    <tr>
      <th>2.3</th>
      <td>16</td>
      <td>12</td>
    </tr>
    <tr>
      <th>2.7</th>
      <td>12</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>15</td>
      <td>9</td>
    </tr>
    <tr>
      <th>3.3</th>
      <td>5</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3.7</th>
      <td>2</td>
      <td>12</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>6</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<p>The formula for the KL Divergence is 
<img alt="kld" src="../kld.png" /></p>
<p>The <img alt="ratio" src="../ratio.png" /> $ part is a ratio. Therefore, if the two distributions P and Q are almost identical, the probability of x in distribution P will be almost equal to the probability of x in distribution Q, so the ratio will be close to 1. <img alt="ratio_res" src="../ratio_res.png" />
Since the log of a number close to 1 is close to 0, summing multiple numbers close to 0 will result in a low KL Divergence.</p>
<pre><code class="python">def kl_divergence(P, Q):
    kl = 0
    for i in range(len(P)):
        kl += P[i] * np.log(P[i]/Q[i])
    return np.round(kl, 3)
</code></pre>

<p><strong>Steps to calculate KL Divergence for discrete data:</strong>
1. Calculate the probabilities for the two distributions from the data
2. Apply the formula</p>
<pre><code class="python"># Calculate probability distribution
grades['P(x)'] = grades['2018'].apply(lambda x: x/grades['2018'].sum())
grades['Q(x)'] = grades['2019'].apply(lambda x: x/grades['2019'].sum())
display(grades)
ax = sns.lineplot(data=grades, x=grades.index, y=&quot;P(x)&quot;, label=&quot;P(x)&quot;)
ax = sns.lineplot(data=grades, x=grades.index, y=&quot;Q(x)&quot;, label=&quot;Q(x)&quot;)
ax.set(ylabel='Probability', xlabel='Grade')
plt.show()
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2018</th>
      <th>2019</th>
      <th>P(x)</th>
      <th>Q(x)</th>
    </tr>
    <tr>
      <th>Grade</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>9</td>
      <td>4</td>
      <td>0.09</td>
      <td>0.040816</td>
    </tr>
    <tr>
      <th>1.3</th>
      <td>5</td>
      <td>18</td>
      <td>0.05</td>
      <td>0.183673</td>
    </tr>
    <tr>
      <th>1.7</th>
      <td>12</td>
      <td>18</td>
      <td>0.12</td>
      <td>0.183673</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>18</td>
      <td>13</td>
      <td>0.18</td>
      <td>0.132653</td>
    </tr>
    <tr>
      <th>2.3</th>
      <td>16</td>
      <td>12</td>
      <td>0.16</td>
      <td>0.122449</td>
    </tr>
    <tr>
      <th>2.7</th>
      <td>12</td>
      <td>7</td>
      <td>0.12</td>
      <td>0.071429</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>15</td>
      <td>9</td>
      <td>0.15</td>
      <td>0.091837</td>
    </tr>
    <tr>
      <th>3.3</th>
      <td>5</td>
      <td>3</td>
      <td>0.05</td>
      <td>0.030612</td>
    </tr>
    <tr>
      <th>3.7</th>
      <td>2</td>
      <td>12</td>
      <td>0.02</td>
      <td>0.122449</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>6</td>
      <td>2</td>
      <td>0.06</td>
      <td>0.020408</td>
    </tr>
  </tbody>
</table>
</div>

<p><img alt="png" src="../output_15_1.png" /></p>
<pre><code class="python">px = grades['P(x)'].to_numpy()
qx = grades['Q(x)'].to_numpy()
print(kl_divergence(px, qx))
print(kl_divergence(qx, px))
</code></pre>

<pre><code>0.242
0.314
</code></pre>
<h4 id="the-kl-divergence-between-p-and-q-is-0242">The KL Divergence between P and Q is 0.242</h4>
<h4 id="the-kl-divergence-between-q-and-p-is-0314">The KL Divergence between Q and P is 0.314</h4>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../.." title="Advanced Data Mining" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Advanced Data Mining
              </span>
            </div>
          </a>
        
        
          <a href="../../Clustream/clustream/" title="Clustream" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Clustream
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.b806dc00.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
    
  </body>
</html>